{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iMRk1LWalY7k"
   },
   "outputs": [],
   "source": [
    "#nltk is string processing library\n",
    "\n",
    "#spacy is object oriented language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qupNAhM8zdoU"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkL9YAmbi1O5",
    "outputId": "02eb1b20-993f-4994-da80-25bca76a0e49"
   },
   "outputs": [],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-3nLvw-zzQl",
    "outputId": "490ce0b8-1f9c-4a95-d533-9c9bb1b38c40"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3Xfloh03z20W"
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ATGdQHfdfq2d"
   },
   "outputs": [],
   "source": [
    "text=nlp(\"Dr. Raman is my mother. She loves me and cares for me. When I am in any kind of trouble I seek help and solace from her. She gives me generously of her time, and does all she can to comfort me and make me happy.My mother always wishes me well, and prays for my good health, happiness and success. I cannot thank my mother enough for all that she does for me. I am grateful to God for giving me such a wonderful mother. I love my mother, and hope I can make her proud of me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z5yJar0zj0jL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Raman is my mother.\n",
      "She loves me and cares for me.\n",
      "When I am in any kind of trouble I seek help and solace from her.\n",
      "She gives me generously of her time, and does all she can to comfort me and make me happy.\n",
      "My mother always wishes me well, and prays for my good health, happiness and success.\n",
      "I cannot thank my mother enough for all that she does for me.\n",
      "I am grateful to God for giving me such a wonderful mother.\n",
      "I love my mother, and hope I can make her proud of me.\n"
     ]
    }
   ],
   "source": [
    "for i in text.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Raman\n",
      "is\n",
      "my\n",
      "mother\n",
      ".\n",
      "She\n",
      "loves\n",
      "me\n",
      "and\n",
      "cares\n",
      "for\n",
      "me\n",
      ".\n",
      "When\n",
      "I\n",
      "am\n",
      "in\n",
      "any\n",
      "kind\n",
      "of\n",
      "trouble\n",
      "I\n",
      "seek\n",
      "help\n",
      "and\n",
      "solace\n",
      "from\n",
      "her\n",
      ".\n",
      "She\n",
      "gives\n",
      "me\n",
      "generously\n",
      "of\n",
      "her\n",
      "time\n",
      ",\n",
      "and\n",
      "does\n",
      "all\n",
      "she\n",
      "can\n",
      "to\n",
      "comfort\n",
      "me\n",
      "and\n",
      "make\n",
      "me\n",
      "happy\n",
      ".\n",
      "My\n",
      "mother\n",
      "always\n",
      "wishes\n",
      "me\n",
      "well\n",
      ",\n",
      "and\n",
      "prays\n",
      "for\n",
      "my\n",
      "good\n",
      "health\n",
      ",\n",
      "happiness\n",
      "and\n",
      "success\n",
      ".\n",
      "I\n",
      "can\n",
      "not\n",
      "thank\n",
      "my\n",
      "mother\n",
      "enough\n",
      "for\n",
      "all\n",
      "that\n",
      "she\n",
      "does\n",
      "for\n",
      "me\n",
      ".\n",
      "I\n",
      "am\n",
      "grateful\n",
      "to\n",
      "God\n",
      "for\n",
      "giving\n",
      "me\n",
      "such\n",
      "a\n",
      "wonderful\n",
      "mother\n",
      ".\n",
      "I\n",
      "love\n",
      "my\n",
      "mother\n",
      ",\n",
      "and\n",
      "hope\n",
      "I\n",
      "can\n",
      "make\n",
      "her\n",
      "proud\n",
      "of\n",
      "me\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Raman\n",
      "is\n",
      "my\n",
      "mother\n",
      ".\n",
      "She\n",
      "loves\n",
      "me\n",
      "and\n",
      "cares\n",
      "for\n",
      "me\n",
      ".\n",
      "When\n",
      "I\n",
      "am\n",
      "in\n",
      "any\n",
      "kind\n",
      "of\n",
      "trouble\n",
      "I\n",
      "seek\n",
      "help\n",
      "and\n",
      "solace\n",
      "from\n",
      "her\n",
      ".\n",
      "She\n",
      "gives\n",
      "me\n",
      "generously\n",
      "of\n",
      "her\n",
      "time\n",
      ",\n",
      "and\n",
      "does\n",
      "all\n",
      "she\n",
      "can\n",
      "to\n",
      "comfort\n",
      "me\n",
      "and\n",
      "make\n",
      "me\n",
      "happy\n",
      ".\n",
      "My\n",
      "mother\n",
      "always\n",
      "wishes\n",
      "me\n",
      "well\n",
      ",\n",
      "and\n",
      "prays\n",
      "for\n",
      "my\n",
      "good\n",
      "health\n",
      ",\n",
      "happiness\n",
      "and\n",
      "success\n",
      ".\n",
      "I\n",
      "can\n",
      "not\n",
      "thank\n",
      "my\n",
      "mother\n",
      "enough\n",
      "for\n",
      "all\n",
      "that\n",
      "she\n",
      "does\n",
      "for\n",
      "me\n",
      ".\n",
      "I\n",
      "am\n",
      "grateful\n",
      "to\n",
      "God\n",
      "for\n",
      "giving\n",
      "me\n",
      "such\n",
      "a\n",
      "wonderful\n",
      "mother\n",
      ".\n",
      "I\n",
      "love\n",
      "my\n",
      "mother\n",
      ",\n",
      "and\n",
      "hope\n",
      "I\n",
      "can\n",
      "make\n",
      "her\n",
      "proud\n",
      "of\n",
      "me\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in text.sents:\n",
    "    for j in i:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nlpp=nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex=\"Dr. Raman is my mother. She loves me and cares for me. When I am in any kind of trouble I seek help and solace from her. She gives me generously of her time, and does all she can to comfort me and make me happy.My mother always wishes me well, and prays for my good health, happiness and success. I cannot thank my mother enough for all that she does for me. I am grateful to God for giving me such a wonderful mother. I love my mother, and hope I can make her proud of me.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Raman is my mother.',\n",
       " 'She loves me and cares for me.',\n",
       " 'When I am in any kind of trouble I seek help and solace from her.',\n",
       " 'She gives me generously of her time, and does all she can to comfort me and make me happy.My mother always wishes me well, and prays for my good health, happiness and success.',\n",
       " 'I cannot thank my mother enough for all that she does for me.',\n",
       " 'I am grateful to God for giving me such a wonderful mother.',\n",
       " 'I love my mother, and hope I can make her proud of me.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokenize(tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.',\n",
       " 'Raman',\n",
       " 'is',\n",
       " 'my',\n",
       " 'mother',\n",
       " '.',\n",
       " 'She',\n",
       " 'loves',\n",
       " 'me',\n",
       " 'and',\n",
       " 'cares',\n",
       " 'for',\n",
       " 'me',\n",
       " '.',\n",
       " 'When',\n",
       " 'I',\n",
       " 'am',\n",
       " 'in',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'trouble',\n",
       " 'I',\n",
       " 'seek',\n",
       " 'help',\n",
       " 'and',\n",
       " 'solace',\n",
       " 'from',\n",
       " 'her',\n",
       " '.',\n",
       " 'She',\n",
       " 'gives',\n",
       " 'me',\n",
       " 'generously',\n",
       " 'of',\n",
       " 'her',\n",
       " 'time',\n",
       " ',',\n",
       " 'and',\n",
       " 'does',\n",
       " 'all',\n",
       " 'she',\n",
       " 'can',\n",
       " 'to',\n",
       " 'comfort',\n",
       " 'me',\n",
       " 'and',\n",
       " 'make',\n",
       " 'me',\n",
       " 'happy.My',\n",
       " 'mother',\n",
       " 'always',\n",
       " 'wishes',\n",
       " 'me',\n",
       " 'well',\n",
       " ',',\n",
       " 'and',\n",
       " 'prays',\n",
       " 'for',\n",
       " 'my',\n",
       " 'good',\n",
       " 'health',\n",
       " ',',\n",
       " 'happiness',\n",
       " 'and',\n",
       " 'success',\n",
       " '.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'not',\n",
       " 'thank',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'enough',\n",
       " 'for',\n",
       " 'all',\n",
       " 'that',\n",
       " 'she',\n",
       " 'does',\n",
       " 'for',\n",
       " 'me',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'grateful',\n",
       " 'to',\n",
       " 'God',\n",
       " 'for',\n",
       " 'giving',\n",
       " 'me',\n",
       " 'such',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'mother',\n",
       " '.',\n",
       " 'I',\n",
       " 'love',\n",
       " 'my',\n",
       " 'mother',\n",
       " ',',\n",
       " 'and',\n",
       " 'hope',\n",
       " 'I',\n",
       " 'can',\n",
       " 'make',\n",
       " 'her',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "word_tokenize(tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Doc is a single processed text document—an object containing tokens and linguistic annotations like parts of speech and entities.\\n\\n\\nA Corpus is a collection of multiple Docs, representing a larger body of text used for analysis or training.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''A Doc is a single processed text document—an object containing tokens and linguistic annotations like parts of speech and entities.\n",
    "\\n\n",
    "A Corpus is a collection of multiple Docs, representing a larger body of text used for analysis or training.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(\"Tesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. Its name is a tribute to inventor and electrical engineer Nikola Tesla. In February 2004, Elon Musk led Tesla's first funding round and became the company's chairman; in 2008, he was named chief executive officer. In 2008, the company began production of its first car model, the Roadster sports car, followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, the Tesla Semi truck in 2022 and the Cybertruck pickup truck in 2023.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=nlp(\"She ate my whole breakfast so i am crying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: She base form: she\n",
      "Original Text: ate base form: eat\n",
      "Original Text: my base form: my\n",
      "Original Text: whole base form: whole\n",
      "Original Text: breakfast base form: breakfast\n",
      "Original Text: so base form: so\n",
      "Original Text: i base form: I\n",
      "Original Text: am base form: be\n",
      "Original Text: crying base form: cry\n",
      "Original Text: . base form: .\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "for i in d:\n",
    "    print(\"Original Text:\",i,\"base form:\",i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: She POS: PRON\n",
      "Original Text: ate POS: VERB\n",
      "Original Text: my POS: PRON\n",
      "Original Text: whole POS: ADJ\n",
      "Original Text: breakfast POS: NOUN\n",
      "Original Text: so POS: ADV\n",
      "Original Text: i POS: PRON\n",
      "Original Text: am POS: AUX\n",
      "Original Text: crying POS: VERB\n",
      "Original Text: . POS: PUNCT\n"
     ]
    }
   ],
   "source": [
    "#Parts of speech\n",
    "for i in d:\n",
    "    print(\"Original Text:\",i,\"POS:\",i.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=nlp(\"Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in Cupertino, California on April 1, 1976. In 2024, Apple announced a $2 billion investment in artificial intelligence research in collaboration with Stanford University.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Apple || Entity Name: ORG\n",
      "Original Text: Inc. || Entity Name: ORG\n",
      "Original Text: founded || Entity Name: \n",
      "Original Text: Steve || Entity Name: PERSON\n",
      "Original Text: Jobs || Entity Name: PERSON\n",
      "Original Text: , || Entity Name: \n",
      "Original Text: Steve || Entity Name: PERSON\n",
      "Original Text: Wozniak || Entity Name: PERSON\n",
      "Original Text: , || Entity Name: \n",
      "Original Text: Ronald || Entity Name: PERSON\n",
      "Original Text: Wayne || Entity Name: PERSON\n",
      "Original Text: Cupertino || Entity Name: GPE\n",
      "Original Text: , || Entity Name: \n",
      "Original Text: California || Entity Name: GPE\n",
      "Original Text: April || Entity Name: DATE\n",
      "Original Text: 1 || Entity Name: DATE\n",
      "Original Text: , || Entity Name: DATE\n",
      "Original Text: 1976 || Entity Name: DATE\n",
      "Original Text: . || Entity Name: \n",
      "Original Text: 2024 || Entity Name: DATE\n",
      "Original Text: , || Entity Name: \n",
      "Original Text: Apple || Entity Name: ORG\n",
      "Original Text: announced || Entity Name: \n",
      "Original Text: $ || Entity Name: MONEY\n",
      "Original Text: 2 || Entity Name: MONEY\n",
      "Original Text: billion || Entity Name: MONEY\n",
      "Original Text: investment || Entity Name: \n",
      "Original Text: artificial || Entity Name: \n",
      "Original Text: intelligence || Entity Name: \n",
      "Original Text: research || Entity Name: \n",
      "Original Text: collaboration || Entity Name: \n",
      "Original Text: Stanford || Entity Name: ORG\n",
      "Original Text: University || Entity Name: ORG\n",
      "Original Text: . || Entity Name: \n"
     ]
    }
   ],
   "source": [
    "#Named Entity Recognition\n",
    "for i in a:\n",
    "    if i.is_stop==False:\n",
    "        print(\"Original Text:\",i,\"|| Entity Name:\",i.ent_type_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: China || GPE\n",
      "Original Text: has || \n",
      "Original Text: a || \n",
      "Original Text: gdp || \n",
      "Original Text: of || \n",
      "Original Text: 20 || MONEY\n",
      "Original Text: $ || MONEY\n",
      "Original Text: and || \n",
      "Original Text: is || \n",
      "Original Text: a || \n",
      "Original Text: city || \n",
      "Original Text: where || \n",
      "Original Text: Apple || ORG\n",
      "Original Text: products || \n",
      "Original Text: are || \n",
      "Original Text: formed || \n",
      "Original Text: since || \n",
      "Original Text: july || DATE\n",
      "Original Text: 2000 || DATE\n",
      "Original Text: by || \n",
      "Original Text: Mr. || \n",
      "Original Text: Ram || PERSON\n"
     ]
    }
   ],
   "source": [
    "x=nlp(\"China has a gdp of 20$ and is a city where Apple products are formed since july 2000 by Mr. Ram\")\n",
    "for i in x:\n",
    "    print(\"Original Text:\",i,\"||\",i.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "incorporated\n",
      "July\n",
      "2003\n",
      "Martin\n",
      "Eberhard\n",
      "Marc\n",
      "Tarpenning\n",
      "Tesla\n",
      "Motors\n",
      ".\n",
      "tribute\n",
      "inventor\n",
      "electrical\n",
      "engineer\n",
      "Nikola\n",
      "Tesla\n",
      ".\n",
      "February\n",
      "2004\n",
      ",\n",
      "Elon\n",
      "Musk\n",
      "led\n",
      "Tesla\n",
      "funding\n",
      "round\n",
      "company\n",
      "chairman\n",
      ";\n",
      "2008\n",
      ",\n",
      "named\n",
      "chief\n",
      "executive\n",
      "officer\n",
      ".\n",
      "2008\n",
      ",\n",
      "company\n",
      "began\n",
      "production\n",
      "car\n",
      "model\n",
      ",\n",
      "Roadster\n",
      "sports\n",
      "car\n",
      ",\n",
      "followed\n",
      "Model\n",
      "S\n",
      "sedan\n",
      "2012\n",
      ",\n",
      "Model\n",
      "X\n",
      "SUV\n",
      "2015\n",
      ",\n",
      "Model\n",
      "3\n",
      "sedan\n",
      "2017\n",
      ",\n",
      "Model\n",
      "Y\n",
      "crossover\n",
      "2020\n",
      ",\n",
      "Tesla\n",
      "Semi\n",
      "truck\n",
      "2022\n",
      "Cybertruck\n",
      "pickup\n",
      "truck\n",
      "2023\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in doc:\n",
    "    if i.is_stop==False:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=nlp(\"three 2 $ sarabdeep@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "three"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].like_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3].like_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2].is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
